# Merck Co-Op Spring 2024

Code repository for deep learning interpretability project. 

Neural Networks are widely considered to be "BlackBox" Models and the interpretability of Deep Learning Models are still an area of active research . In order to better understand the interpretability, my peers and I performed some experiments leveraging existing statistical methods. 

We conduct experiments on MNIST Dataset and for purpose of interpretability we  are working on CNN model . 

Some techniques explored :-
1. Conformal Predictions
2. Integrated Gradients
3. SHAP

   We will perform further experiments to get a better understanding than what we have acheived
